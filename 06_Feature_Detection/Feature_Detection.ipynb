{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Detection\n",
    "This notebook explains the basic concepts of feature detectors and feature descriptors in the field of image processing and computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are features in an image?\n",
    "A feature is a piece of information that describes an image or part of an image. For example edges and corners  are features which can be detected in an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature points (key points)\n",
    "A feature point, or a key point, on an image is a point which has unique and identifiable properties. These unique properties can be used to match the key point to another key point in a different image. For example an edge point or a corner point in an image can be considered as feature points. Edge points suffer from aperture problem because an edge point in one image can not be uniquely matched to an edge point in another image.\n",
    "Corner points are better feature points because it is easier to match a corner point in one image to a corner point in another image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a feature detector?\n",
    "\n",
    "Feature detection is a general term which involves reducing the amount of information required to describe a set of data. In image processing and computer vision a feature detector is a process that detects the presence of certain attribute or aspect of the visual scene. For example an edge is considered a feature in an image and edge detection is one kind of feature detectors. \n",
    "\n",
    "There are generally two methods for feature detection and presentation, global features and local features. In global methods features are extracted from the entire image and the original image is represented by a set of global features, called feature vector. The feature vectors usually have lower dimensions than the original image. In contrast, in the local feature presentation, the features are extracted from a local neighborhood around **interest points** or **key points**. \n",
    "\n",
    "* Examples of global feature presentation:\n",
    "    * Principal Component Analysis (PCA)\n",
    "    * Independent Component Analysis (ICA)\n",
    "    * Linear Discriminant Analysis (LDA)\n",
    "    * ...\n",
    "* Examples of local feature presentation:\n",
    "    * Edges\n",
    "    * Corners\n",
    "    * Blobs\n",
    "    * ...\n",
    "    \n",
    "** Note:**\n",
    "Feature detection is not the same as feature selection. \n",
    "Feature detectors are processes that identify features in local neighborhood by processing the information surrounding a pixel. In other words, in feature detection the information in the original data is combined (transformed) into a lower dimensional space. However, in feature selection a subset of existing data or features is selected without transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristics of good feature detectors\n",
    "\n",
    "Good features in an image should be as unique as possible and they should allow efficient matching of features between images. A good feature detector should have the following properties:\n",
    "* **Invariance:** A ideal feature detector should be invariant to scaling, rotation, translation, perspective projection, image intensity, and photometric deformations.\n",
    "* **Robustness:** The feature detector should be able to detect the same feature independent of noise in the image intensity. \n",
    "* **Accuracy:** The feature detector should accurately determine the location of a feature.\n",
    "* **Efficiency:** The feature detection algorithm should be computationally efficient.\n",
    "* **Quantity:** The ideal feature detector should be able to detect all of the features in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harris corner detector\n",
    "The basic idea of Harris corner detector is that if we look through a small window (small kernel) at a particular location in the image and multiply each pixel by the corresponding value in the kernel and sum all the values then:\n",
    "* if the kernel is located at a flat region of an image then moving it in any direction does not change the result.\n",
    "* If the kernel is located on an edge then moving the kernel parallel to an edge then the result will not change but if move the kernel perpendicular to an edge then the result will change.\n",
    "* If the kernel is located on a corner (intersection of two edges), then moving the kernel in any direction will change the result. We can capture this concept mathematically:\n",
    "$$\\large E(u,v) = \\sum\\limits_{x,y} {w(x,y){{\\left[ {f(x + {\\Delta x},y + {\\Delta y}) - f(x,y)} \\right]}^2}} $$\n",
    "\n",
    "\n",
    "where $w(x,y)$ is the kernel (window) and $f(x,y)$ is the image intensity at pixel location $(x,y)$ and ${\\Delta x}$ and ${\\Delta y}$ are small movements in $x$ and $y$ directions.\n",
    "\n",
    "If we expand the above equation by using the first order Taylor series then we get:\n",
    "\n",
    "$$\\large E(u,v) = \\sum\\limits_{x,y} {w(x,y){{\\left[ {f({x},{y}) + \\left[ {\\begin{array}{*{20}{c}}\n",
    "{{\\textstyle{{\\partial f({x},{y})} \\over {\\partial x}}}}&{{\\textstyle{{\\partial f({x},{y})} \\over {\\partial y}}}}\n",
    "\\end{array}} \\right]\\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\Delta x}\\\\\n",
    "{\\Delta y}\n",
    "\\end{array}} \\right] - f(x,y)} \\right]}^2}} $$\n",
    "\n",
    "----\n",
    "$$\\large E(u,v) = \\sum\\limits_{x,y} {w(x,y){{{\\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\Delta x}&{\\Delta y}\n",
    "\\end{array}} \\right]\\left( {\\left[ {\\begin{array}{*{20}{c}}\n",
    "{{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial x}}}}\\\\\n",
    "{{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial y}}}}\n",
    "\\end{array}} \\right]\\left[ {\\begin{array}{*{20}{c}}\n",
    "{{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial x}}}}&{{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial y}}}}\n",
    "\\end{array}} \\right]} \\right)\\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\Delta x}\\\\\n",
    "{\\Delta y}\n",
    "\\end{array}} \\right]}}}} $$\n",
    "\n",
    "----\n",
    "$$\\large E(u,v) = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\Delta x}&{\\Delta y}\n",
    "\\end{array}} \\right]\\sum\\limits_{x,y} {w(x,y){{{\\left( {\\left[ {\\begin{array}{*{20}{c}}\n",
    "{{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial x}}}}\\\\\n",
    "{{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial y}}}}\n",
    "\\end{array}} \\right]\\left[ {\\begin{array}{*{20}{c}}\n",
    "{{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial x}}}}&{{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial y}}}}\n",
    "\\end{array}} \\right]} \\right)\\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\Delta x}\\\\\n",
    "{\\Delta y}\n",
    "\\end{array}} \\right]}}}} $$\n",
    "\n",
    "----\n",
    "$$\\large E(u,v) = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\Delta x}&{\\Delta y}\n",
    "\\end{array}} \\right]\\sum\\limits_{x,y} {w(x,y){{{\n",
    "\\left[ {\\begin{array}{*{20}{c}}\n",
    "{ {{{\\left( {{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial x}}}} \\right)}^2}} }&{ {{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial x}}}{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial y}}}} }\\\\\n",
    "{ {{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial x}}}{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial y}}}} }&{{{{\\left( {{\\textstyle{{\\partial f({x_i},{y_i})} \\over {\\partial y}}}} \\right)}^2}} }\n",
    "\\end{array}} \\right]\n",
    "\\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\Delta x}\\\\\n",
    "{\\Delta y}\n",
    "\\end{array}} \\right]}}}} $$\n",
    "\n",
    "----\n",
    "$$\\large E(u,v) = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\Delta x}&{\\Delta y}\n",
    "\\end{array}} \\right] A\\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\Delta x}\\\\\n",
    "{\\Delta y}\n",
    "\\end{array}} \\right] $$\n",
    " where \n",
    "$$\\large A = \\sum\\limits_{x,y} {w(x,y)\\left[ {\\begin{array}{*{20}{c}}\n",
    "{I_x^2}&{{I_x}{I_y}}\\\\\n",
    "{{I_x}{I_y}}&{I_y^2}\n",
    "\\end{array}} \\right]} $$\n",
    "\n",
    "Matrix $A$ is called the Harris matrix. This matrix is symmetric and Positive semi-definite. The Eigen values of this matrix which are λ1 and λ2 (λ1 >= λ2) , determine the sensitivity of the matrix $A$ to small movements.\n",
    "* If Both λ1 and  λ2 are small then that means that there are no edges or corner in that position and the corresponding point is in a flat region.\n",
    "* If λ1 is large but λ2 is small then that means that the point is on an edge (no corner).\n",
    "* If both λ1 and λ2 are large then the point is on a corner \n",
    "\n",
    "There is another alternative to Eigenvalues to measure the response of the Harris detector:\n",
    "\n",
    "$$R({{\\bf{A}}}) = \\det (A) - \\kappa {\\rm{trac}}{{\\rm{e}}^2}({\\bf{A}})=λ1λ2-\\alpha(λ1+λ2)$$\n",
    "\n",
    "where $R({{\\bf{A}}})$ is the response function. The value of the constant $\\alpha$ is usually between 0.04 and 0.15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Harris detector\n",
    "\n",
    "* Filter the image with a Gaussian\n",
    "* Estimate gradients in x and y directions. (This step and the last one could be performed together by convolving the image with the derivative of Gaussians in x and y directions.\n",
    "* Calculate $I_x^2$ , $I_y^2$ , and $I_x I_y$\n",
    "* Smooth the three calculated images with a Gaussian\n",
    "* For each pixel calculate the matrix A on a local neighborhood \n",
    "* Compute the response function R(A)\n",
    "* Choose the best candidates for corners by selecting thresholds on the response function R(A) \n",
    "* Apply non-maximal suppression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from skimage import data\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "# import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, interact,interactive, fixed, FloatSlider, IntSlider, Label, Checkbox, FloatRangeSlider\n",
    "import cv2 as cv\n",
    "plt.rcParams['image.interpolation'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell is a utility function to arrange the Ipython widgets in a grid.\n",
    "from IPython.display import display\n",
    "from ipywidgets import Layout,HBox,VBox,interact,interactive, fixed, FloatSlider, IntSlider, Label, Checkbox, FloatRangeSlider\n",
    "\n",
    "def arrange_widgets_in_grid(widgets_list,number_of_col=2,label_width_percent=50,height_pixels=40):\n",
    "    \"\"\"\n",
    "    This function arranges the widgets in a two dimensional grid.\n",
    "    According to the Ipython widgets documentation: \"You cannot change the width of the internal description field\".\n",
    "    This means that if the description for a widget, such as a slider, is too long then it can not be properly \n",
    "    displayed. In order to display a long description it should be put in \"HBox\" widget.\n",
    "    This function uses combinations of HBox, VBox, and Layout to display the widgets\n",
    "    in a grid and allow long widget descriptions to be properly displayed.\n",
    "    Farhad Kamangar\n",
    "    Feb. 4, 2017\n",
    "    \"\"\"\n",
    "    label_layout=Layout(width=\"{0:d}%\".format(int(label_width_percent)), \n",
    "                height=\"{0:d}px\".format(height_pixels))\n",
    "    widget_layout=Layout(width=\"{0:d}%\".format(int(100-(label_width_percent))), \n",
    "                height=\"{0:d}px\".format(height_pixels))\n",
    "    hbox_layout=Layout(border='2px solid blue',width='100%',\n",
    "            display='inline-flex',flex_flow='row wrap')\n",
    "    vbox_layout=Layout(border='2px solid black',width=\"{0:d}%\".format(int(90/number_of_col)),\n",
    "        display='inline-flex',flex_flow='row wrap')\n",
    "    column_widgets = [[] for i in range(number_of_col)]\n",
    "    for k,current_widget in enumerate(widgets_list.children):\n",
    "        col=k%number_of_col\n",
    "        current_description=widgets_list.children[k].description\n",
    "        widgets_list.children[k].description=\"\"       \n",
    "        current_hbox_label=HBox(layout=label_layout)\n",
    "        current_hbox_label.children=[Label(current_description)]\n",
    "        current_hbox_widget=HBox(layout=widget_layout)\n",
    "        current_hbox_widget.children=[widgets_list.children[k]]\n",
    "        current_hbox = HBox(layout=hbox_layout)             \n",
    "        current_hbox.children=[current_hbox_label,current_hbox_widget]\n",
    "\n",
    "        column_widgets[col].append(current_hbox)\n",
    "    list_of_vboxes=[]\n",
    "\n",
    "    for k in range(number_of_col):\n",
    "        current_vbox=VBox(column_widgets[k])\n",
    "        current_vbox.layout=vbox_layout\n",
    "        list_of_vboxes.append(current_vbox)\n",
    "    master_widget=HBox(list_of_vboxes)\n",
    "    widgets_list.children=(master_widget,)\n",
    "    display(widgets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:567: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  silent = bool(old_value == new_value)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5968ad04d84f66b71d9716e5355490"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.ndimage import convolve\n",
    "# plt.rcParams['image.interpolation'] = 'none'\n",
    "def calculate_and_display_harris_corner_detector(original_image,\n",
    "        gaussian_kernel_size_1=9,\n",
    "        gaussian_kernel_sigma_1=1,\n",
    "        gaussian_kernel_size_2=17,\n",
    "        gaussian_kernel_sigma_2=5.0,\n",
    "        alpha=0.04,  # Recommended value between .04 and .06\n",
    "        non_maxima_neighborhood_size=7,\n",
    "        normalized_response_threshold=0.001,\n",
    "        display_absolute=False):\n",
    "    horizontal_kernel = np.array([[ 1.,  2,  1],[ 0,  0,  0],[-1,-2,-1]])\n",
    "    vertical_kernel = np.array([[ -1.,  0,  1],[ -2,  0,  2],[-1,0,1]])\n",
    "    # Normalize the kernels\n",
    "    kernel_sum=abs(np.sum(horizontal_kernel))\n",
    "    horizontal_kernel= horizontal_kernel/kernel_sum if kernel_sum else horizontal_kernel\n",
    "    kernel_sum=abs(np.sum(vertical_kernel))\n",
    "    vertical_kernel= vertical_kernel/kernel_sum if kernel_sum else vertical_kernel\n",
    "    #     GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]])\n",
    "    smooth_original_image = cv.GaussianBlur(original_image, \n",
    "        (gaussian_kernel_size_1,gaussian_kernel_size_1), gaussian_kernel_sigma_1)\n",
    "\n",
    "    # calculate the gradients in x direction\n",
    "    i_x = scipy.ndimage.convolve(smooth_original_image, vertical_kernel)\n",
    "    # Claculate the gradients in the y direction\n",
    "    i_y = scipy.ndimage.convolve(smooth_original_image, horizontal_kernel)\n",
    "    # Calculate the elements of the Harris matrix\n",
    "    i_xx = i_x* i_x\n",
    "    i_xy = i_x* i_y\n",
    "    i_yy = i_y* i_y\n",
    "#     GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]])\n",
    "    s_xx = cv.GaussianBlur(i_xx, (gaussian_kernel_size_2,gaussian_kernel_size_2), gaussian_kernel_sigma_2)\n",
    "    s_xy = cv.GaussianBlur(i_xy, (gaussian_kernel_size_2,gaussian_kernel_size_2), gaussian_kernel_sigma_2)\n",
    "    s_yy = cv.GaussianBlur(i_yy, (gaussian_kernel_size_2,gaussian_kernel_size_2), gaussian_kernel_sigma_2)\n",
    "    # Calculate the response of the Harris detector at each point\n",
    "    det_of_a = (s_xx* s_yy) - (s_xy* s_xy)\n",
    "    trace_of_a = s_xx + s_yy\n",
    "    R = det_of_a - alpha*(trace_of_a*trace_of_a)\n",
    "    thresholded_response=np.copy(R)\n",
    "    threshold=normalized_response_threshold * np.max(R)\n",
    "    thresholded_response[R < threshold]=0.0\n",
    "    # suppress non-maxima points in a neighborhood\n",
    "    temp_maximas=scipy.ndimage.maximum_filter(thresholded_response, size=non_maxima_neighborhood_size)\n",
    "    mask=[temp_maximas==thresholded_response] and [R>=threshold]\n",
    "    output_response=np.zeros(R.shape)\n",
    "    output_response[mask]=1\n",
    "    # Display results after each step\n",
    "    fig1, axes_array = plt.subplots(2, 3)\n",
    "    fig1.set_size_inches(9,6)\n",
    "    axes_array=np.ravel(axes_array)\n",
    "    \n",
    "    image_plot = axes_array[0].imshow(original_image ,cmap=plt.cm.gray) # Show the original image\n",
    "    # axes_array[0].axis('off')\n",
    "    axes_array[0].set(title='Original image')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[1].imshow(np.abs(i_x),cmap=plt.cm.gray) # Show absolute value of the filtered image\n",
    "    else:\n",
    "        image_plot = axes_array[1].imshow(i_x,cmap=plt.cm.gray) # Show the filtered image\n",
    "    axes_array[1].axis('off')\n",
    "    axes_array[1].set(title='Horizontal Edges')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[2].imshow(np.abs(i_y),cmap=plt.cm.gray) \n",
    "    else:\n",
    "        image_plot = axes_array[2].imshow(i_y,cmap=plt.cm.gray) \n",
    "    axes_array[2].axis('off')\n",
    "    axes_array[2].set(title='Vertical Edges')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[3].imshow(np.abs(R),cmap=plt.cm.gray) \n",
    "    else:\n",
    "        image_plot = axes_array[3].imshow(R,cmap=plt.cm.gray) \n",
    "    axes_array[3].axis('off')\n",
    "    axes_array[3].set(title='Harris Response')\n",
    "    \n",
    "    image_plot = axes_array[4].imshow(thresholded_response,cmap=plt.cm.gray) \n",
    "    axes_array[4].axis('off')\n",
    "    axes_array[4].set(title='Thresholded Response')\n",
    "    w, h = original_image.shape\n",
    "    output_image = np.empty((w, h, 3))\n",
    "    output_image[:, :, 2] =  output_image[:, :, 1] =  output_image[:, :, 0] =  original_image\n",
    "    # Dilating is not part of Harris corner detection\n",
    "    # It is done so the red dots on the corners can be seen better\n",
    "#     output_response = cv.dilate(output_response,None)\n",
    "    output_image[output_response>0]=[1,0,0]\n",
    "    image_plot = axes_array[5].imshow(output_image) \n",
    "#     image_plot = axes_array[5].imshow(output_response,cmap=plt.cm.gray) \n",
    "    axes_array[5].axis('off')\n",
    "    axes_array[5].set(title='Corners')    \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "current_image=data.checkerboard()/255.\n",
    "# current_image=data.text()/255.\n",
    "# image_size=100\n",
    "# current_image=np.zeros((image_size,image_size))\n",
    "# current_image[int(image_size/4):-int(image_size/4),int(image_size/4):-int(image_size/4)]=1\n",
    "# current_image[int(image_size/3):-int(image_size/3),int(image_size/3):-int(image_size/3)]=0\n",
    "\n",
    "\n",
    "controls=interact(calculate_and_display_harris_corner_detector,\n",
    "    original_image=fixed(current_image),\n",
    "    gaussian_kernel_size_1=IntSlider(min=3,max=51,step=2,\n",
    "                value=3,description='Gaussian Kernel Size #1',continuous_update=False),\n",
    "    gaussian_kernel_sigma_1=FloatSlider(min=0.0, max=10, step=0.01, \n",
    "                value=1.0,description='Gaussian Sigma #1',continuous_update=False),\n",
    "    gaussian_kernel_size_2=IntSlider(min=3,max=51,step=2,\n",
    "                value=3,description='Gaussian Kernel Size #2',continuous_update=False),\n",
    "    gaussian_kernel_sigma_2=FloatSlider(min=0.0, max=10, step=0.01, \n",
    "                value=1,description='Gaussian Sigma #2',continuous_update=False),\n",
    "    alpha=FloatSlider(min=0.01, max=0.5, step=0.01, \n",
    "                value=0.04,description='Alpha',continuous_update=False), \n",
    "    non_maxima_neighborhood_size=IntSlider(min=3, max=51, step=2, value=19,\n",
    "            description='Non-maxima Neighborhood size',continuous_update=False),\n",
    "    normalized_response_threshold=FloatSlider(min=0.0, max=1, step=0.001,readout_format='.4f', \n",
    "                value=0.002,description='Response Threshold',continuous_update=False),\n",
    "                        display_absolute=Checkbox(value=False,description='Display Absolute Values'))\n",
    "# arrange_widgets_in_grid(controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "1d20a67d44bf4323af0e052bcdfdfcff": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
